# RL_Highway_Work



---

# Reinforcement Learning Project: Highway-env
**Date:** March 26, 2024  
**Abstract:** This project involves implementing and experimenting with reinforcement learning methods on different environments within the Highway-env collection. The goal is to explore different configurations and algorithms to understand their impact on learning dynamics and agent behavior.

## Important Dates
- **Configuration Files and Group Registrations Due:** April 10th, 2024
- **Final Submission Due:** April 25th, 2024

## Environments and Problems

### 1. Highway
**File:** `config.py`  
**Description:**  
Implement a deep Q-network (DQN) to navigate the highway environment. Documentation of the training performance and behavioral analysis of the agent should be provided. Observe and describe different learning phases.

### 2. Continuous Actions (Environment TBD)
**File:** `parking.env`  
**Description:**  
Configure this environment for continuous actions. Implement the selected reinforcement learning algorithm and compare the performance and behavior differences with the discrete actions in the Highway environment.

### 3. Third Environment Using Stable Baselines
**File:** `racetrack.env`  
**Description:**  
Utilize the Stable Baselines library to apply a pre-existing algorithm to a third environment. Design experiments to analyze specific aspects of the task and algorithm, such as generalization capabilities, impact of hyperparameters, safety in learning, or predictive accuracy of the model.

## Group Collaboration
Groups consist of up to four members. Each member must contribute to the project documentation and code development. Work division should be clearly documented, highlighting individual contributions.

## Submission Requirements
- **Individual Reports:** Each student submits a report (max 4 pages) detailing their contributions.
- **Code:** All code used in the project, accompanied by a README explaining the common work and setup instructions.
- **Additional Documentation:** Describe the chosen environments, algorithms, design choices, and any training difficulties encountered. 

---
